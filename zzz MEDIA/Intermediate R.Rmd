---
title: "Intermediate R Programming"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Today we are going to go step-by-step through a typical Booth workflow for a regression problem. The steps involved will be:  
  
**1. Loading the Data**  
**2. Understanding the Data**  
**3. Cleaning the Data**  
**4. Performing Analysis**  
**5. Visualizing the Results**  

The dataset we will be working with today is the "mtcars" dataset, which comes preloaded with RStudio. You can load it anytime to practice by simply referencing it in R:
```{r}
print(mtcars)
```

I asked you to download a slightly modified version of the file to allow us to practice some fundamentals. Let's load that version into R and save it as "data":
```{r}
#The read.csv function allows us to load a comma separated values file into our R workspace
#Remember you can use the ? symbol to load the native R help files at any time!
data <- read.csv('D:\\Users\\Jeffrey\\Downloads\\mtcars_missing_data.csv')
#Note that R for Windows requires 2 "\" when calling a filepath 
```

Now that we've loaded the data, the first thing we should do is make sure we understand what the data contains. Let's try a couple functions that will be helpful for doing that!

```{r}
#The str() function tells us the name of each variable in a dataset, its type, and previews some of the values
str(data)
```
```{r}
#The summary() function gives us descriptive statistics for each variable, and crucially the number of missing values!
summary(data)
```
```{r}
#If we just wanted to understand one column in the data, we could do that as well using the $ operator
summary(data$mpg)
```

**Oh no! Jeff is a jerk who has added some missing values to the data. This will ruin our analysis so we have no choice but to learn how to clean data with missings!**

First, let's identify where the missings are in our data using the is.na() function and subsetting syntax we learned last week. Let's find all missings for the mpg variable.
```{r}
#Remember, [] is used to subset. The number before the comma is the row, while the number after the comma is the column.
#If no number is provided, R assumes you want all rows/columns
data[is.na(data$mpg),]
```

It appears that all data for the Tesla Model S in row 33 is missing. In this case, it makes sense to remove this row from our dataset before proceeding. Let's do that now.
```{r}
#The complete.case() funciton is a base R function that identifies rows with no missing data. It will make your life easier
data_non_missing <- data[complete.cases(data),]
#The head() and tail() functions show you the first/last n observations in the data.frame
tail(data_non_missing,5)
```

Note that row 33 is now gone from our data_non_missing data.frame.  
  
Another common data cleaning step is creating categorical variables from numeric ones. For example, let's imagine we do not care about the difference between a 6 cylinder car and an 8 cylinder car. We just want to know if a car has a low amount of cylinders (4) or a high amount of cylinders (>4). Let's create a cyl_status variable to capture this information.
```{r}
#You can assign data to a type by using the as.'type'() function. Here we set our  variable to type factor (or categorical)
#The ifelse function allows you to to specify a logical condition, a value to return if true, and one to return if false
data_non_missing$cyl_status <- as.factor(ifelse(data_non_missing$cyl > 4, 'high', 'low'))
summary(data_non_missing$cyl_status)
```
11 of ours cars have 4 cylinders, while the remaining 21 are V6 or V8s.  
  
Now that we've removed all missings, let's introduce the concept of plotting. First, let's plot miles per gallon since it will eventually become the dependent variable in our regression.
```{r}
#A histogram is a useful plot for showing a univariate distribution. You can specify the number of buckets, e.g. 10
hist(data_non_missing$mpg, 10)
```

Now let's try to understand how other variables relate to miles per gallon. To do this, let's begin by plotting the relationship between a car's weight (wt) and its mpg.
```{r}
#The plot function is a base R package for plotting. Eventually you'll want to use ggplot2 to create the pretty charts we showed last week, but plot is good enough for getting a rough understanding of the data
plot(data_non_missing$wt,data_non_missing$mpg)
```
  
Clearly miles per gallon tends to fall as weight increases, but is this relationship statistically meaningful? Let's find out by running a simple linear regression!  
  
The lm() function stands for 'Linear Model' and is used to run regressions in R. lm() requires a formula detailing the dependent and independent variable(s) in the format 'y ~ x'
```{r}
#You can save your regression model as an object in your R environment the same as any other variable
reg <- lm(mpg~wt,data=data_non_missing)
#Note that I have used the data= argument so I don't have to reference the dataset each variable comes from
#Now let's output the results of the regression using summary()
summary(reg)
```
The summary function outputs the formula for the regression, the range of the residuals, the coefficient estimates and their significance, an R-squared value, and a F-statistic. We can see in our regression that an increase in weight of 1 is associated with a decrease in mpg of -5.3445, which is highly significant. Let's overlay a plot of this linear model on top of our data.
```{r}
#You can overlay a regression line on a plot by simply calling the abline() command and adding the regression model as the argument
plot(data_non_missing$wt,data_non_missing$mpg)
abline(reg)
```
  
Interesting! It seems like the line is too low at the ends, and too high in the middle. Let's explore this further by graphing the residuals.
```{r}
#One of the components of the regression output are the residuals, or the difference between the predicted value and the actual value for given an observation
#The regression output is in the same order as the input data, so we can simply graph our independent variable against our residuals
plot(data_non_missing$wt,reg$residuals)
abline(0,0)
```

As we suspected, the residuals are not normally distributed! Perhaps we should consider adding a squared weight term to our model. A perfect excuse to explore multiple linear regression!
```{r}
#First lets create a squared weight term
data_non_missing$wt2 <- data_non_missing$wt^2

#Multiple linear regression is exactly the same as our prior example, except that additional variables are referenced in the formula statement with a '+' symbol, e.g. 'y ~ x1 + x2'
reg2 <- lm(mpg~wt+wt2,data=data_non_missing)
summary(reg2)
```

Adding a squared term certainly improved our adjusted R-squared. Let's check our residuals again.
```{r}
plot(data_non_missing$wt,reg2$residuals)
abline(0,0)
```
That certainly looks better!  
  
Because base R functions only plot straight lines,  we're going to have to get a little fancy and introduce another important part of regressions in R, the predict() function. The predict function will take a set of independent variable values you give it and output the predict the associated dependent variable value. By creating a sequence of wt measures that are spaced very close together, we will be able to approximate a curve matching our polynomial model. Let's give it a shot.

```{r}
#We want to plot our data from a wt range of 1 to 6. In order to do that let's use the seq() function.
#We'll need a lot of points inbetween to make a smooth-looking curve and a dataframe to store them in
predict_range <- data.frame(wt = seq(1,6,by=0.001), wt2 = seq(1,6,by=0.001)^2)

#Now let's calculate the predicted mpg for each weight using the predict function
#CAUTION: It is paramount that your new_data variables have the EXACT SAME NAME as your regression model, otherwise predict WILL NOT WORK
predict_range$fitted<-predict(reg2,newdata=predict_range)

#Now lets plot the result
plot(data_non_missing$wt,data_non_missing$mpg)
lines(predict_range$wt,predict_range$fitted)
```

Not bad! Obviously this has been a tremendously simplified version of what you will actually do in class, but now you should have the basic skills to get started. Any questions?